{"cells":[{"cell_type":"markdown","metadata":{"id":"T87ULpx324M6"},"source":["# Tutorial 1 PyTorch Basics: Tensor\n","\n","## Tensor\n","\n","<b>The contents of this tutorial is largely based on the book and tutorial notes here[^1].\n","\n","Tensor, also known as tensor, readers may be familiar with this term, because it not only appeared in PyTorch, but also in Theano, TensorFlow,\n","Important data structures in Torch and MxNet. There is no lack of in-depth analysis of the nature of tensors, but from an engineering point of view, it can be simply considered as an array and supports efficient scientific computing. It can be a number (scalar), a one-dimensional array (vector), a two-dimensional array (matrix), and a higher-dimensional array (higher-order data). Tensor is similar to Numpy's ndarrays, but PyTorch's tensor supports GPU acceleration.\n","\n","This section will systematically explain the use of tensor, trying to cover everything, but not every function. For more functions and their usage, readers can view the help documentation by adding `?` to the function name in IPython/Notebook, or refer to the official PyTorch documentation[^1].\n","\n","[^1]: http://docs.pytorch.org </b>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"YDjastGK24M_","executionInfo":{"status":"ok","timestamp":1674219186829,"user_tz":-480,"elapsed":4189,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"6b474111-ee44-4139-d792-623b7d9a4231"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.13.1+cu116'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["# Let's begin\n","from __future__ import print_function\n","import torch  as t\n","t.__version__"]},{"cell_type":"markdown","metadata":{"id":"9EpAAAWr24NB"},"source":["### <b>3.1.1 Basic operations</b>\n","\n","Readers who have studied Numpy will feel very familiar with the content of this section, because the tensor interface is intentionally designed to be similar to Numpy for the convenience of users. But it doesn't matter if you are not familiar with Numpy. This section does not require you to master Numpy first.\n","\n","From the interface point of view, operations on tensor can be divided into two categories:\n","\n","1. `torch.function`, such as `torch.save` etc.\n","2. The other category is `tensor.function`, such as `tensor.view`, etc.\n","\n","For ease of use, most operations on tensor support these two types of interfaces at the same time, and no specific distinction is made in this book, such as `torch.sum (torch.sum(a, b))` and `tensor.sum (a. sum(b))` is functionally equivalent.\n","\n","From the perspective of storage, operations on tensor can be divided into two categories:\n","\n","1. It will not modify its own data, such as `a.add(b)`, the addition result will return a new tensor.\n","2. It will modify its own data, such as `a.add_(b)`, the addition result is still stored in a, and a has been modified.\n","\n","Function names ending with `_` are all inplace methods, which will modify the caller's own data, which need to be distinguished in practical applications.\n","\n","#### <b>Create Tensor</b>\n","\n","There are many ways to create a new tensor in PyTorch, as shown in Table 3-1.\n","\n","Table 3-1: Common ways to create a new tensor\n","\n","|function|function|\n","|:---:|:---:|\n","|Tensor(\\*sizes)|Basic constructor|\n","|tensor(data,)|Constructor similar to np.array|\n","|ones(\\*sizes)|full 1Tensor|\n","|zeros(\\*sizes)|full 0Tensor|\n","|eye(\\*sizes)|diagonal is 1, others are 0|\n","|arange(s,e,step|from s to e, the step size is step|\n","|linspace(s,e,steps)|From s to e, evenly divided into steps|\n","|rand/randn(\\*sizes)|uniform/standard distribution|\n","|normal(mean,std)/uniform(from,to)|normal distribution/uniform distribution|\n","|randperm(m)|random permutation|\n","\n","These creation methods can specify the data type dtype and storage device (cpu/gpu) when creating.\n","\n","\n","Among them, using the `Tensor` function to create a tensor is the most complex and changeable method. It can receive a list and create a tensor based on the list data, or create a tensor according to a specified shape, and pass in other tensors. The following examples A few examples."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fr7nZBBW24NC","executionInfo":{"status":"ok","timestamp":1674219292372,"user_tz":-480,"elapsed":470,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"3ffbb580-0aec-4a5f-c460-bae85241085a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[8.2955e-35, 0.0000e+00, 3.7835e-44],\n","        [0.0000e+00,        nan, 1.4153e-43]])"]},"metadata":{},"execution_count":2}],"source":["# Specify the shape of the tensor\n","a = t.Tensor(2, 3)\n","a # The value depends on the state of the memory space, it may overflow when printing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kceJFmte24ND","executionInfo":{"status":"ok","timestamp":1674196271158,"user_tz":-480,"elapsed":384,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"23b04c3e-39ed-404a-c4fb-523a802c8444"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 2., 3.],\n","        [4., 5., 6.]])"]},"metadata":{},"execution_count":3}],"source":["# Create tensor with list data\n","b = t.Tensor([[1,2,3],[4,5,6]])\n","b"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9b83Zb_c24ND","executionInfo":{"status":"ok","timestamp":1674196284780,"user_tz":-480,"elapsed":370,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"6e759632-46c8-4c26-81a8-21b151ff0247"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]"]},"metadata":{},"execution_count":4}],"source":["b.tolist() # convert tensor to list"]},{"cell_type":"markdown","metadata":{"id":"MmfOE4Ia24NE"},"source":["`tensor.size()` returns `torch.Size` object, which is a subclass of tuple, but its usage is slightly different from tuple"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"CODHBPGD24NE","executionInfo":{"status":"ok","timestamp":1674196295658,"user_tz":-480,"elapsed":362,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"4a6e937d-2c19-4f96-c931-6e6924954e02"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 3])"]},"metadata":{},"execution_count":5}],"source":["b_size = b.size()\n","b_size"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"if1A7wMf24NF","executionInfo":{"status":"ok","timestamp":1674196308760,"user_tz":-480,"elapsed":476,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"8fc5cb03-b2a7-4386-8c0c-2278b86b0480"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":6}],"source":["b.numel() # The total number of elements in b, 2*3, equivalent to"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"0iF137c624NF"},"outputs":[],"source":["# Create a tensor with the same shape as b\n","c = t.Tensor(b_size)\n","# Create a tensor with elements 2 and 3\n","d = t.Tensor((2, 3))\n","c, d"]},{"cell_type":"markdown","metadata":{"id":"YfjvWHAS24NG"},"source":["In addition to `tensor.size()`, you can also use `tensor.shape` to directly view the shape of the tensor, `tensor.shape` is equivalent to `tensor.size()`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIV41qYU24NG"},"outputs":[],"source":["c.shape"]},{"cell_type":"markdown","metadata":{"id":"MdA_yiwK24NG"},"source":["It should be noted that when `t.Tensor(*sizes)` creates a tensor, the system will not allocate space immediately, but will only calculate whether the remaining memory is enough to use. It will only be allocated when the tensor is used, and other operations are created Space allocation is performed immediately after tensor is finished. Examples of other commonly used methods for creating tensors are as follows."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"4NlUaBB224NH"},"outputs":[],"source":["t.ones(2, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IzbkuWQt24NH"},"outputs":[],"source":["t.zeros(2, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XiswL3u24NH"},"outputs":[],"source":["t.arange(1, 6, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GPx0fQBP24NH"},"outputs":[],"source":["t.linspace(1, 10, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IxA4UMZe24NI"},"outputs":[],"source":["t.randn(2, 3, device=t.device('cpu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"6A_iYGiH24NI"},"outputs":[],"source":["t.randperm(5) # random permutation of length 5"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"bOz1Gswu24NI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674219413261,"user_tz":-480,"elapsed":466,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"14417958-50c9-4471-bc40-86783540f00a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 0, 0],\n","        [0, 1, 0]], dtype=torch.int32)"]},"metadata":{},"execution_count":3}],"source":["t.eye(2, 3, dtype=t.int) # Diagonal line is 1, does not require the same number of rows and columns"]},{"cell_type":"markdown","metadata":{"id":"c9_zJCzv24NI"},"source":["`torch.tensor` is a new version of the tensor creation method added in version 0.4, the method used, and the parameters are almost exactly the same as `np.array`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rPCnmaUH24NI"},"outputs":[],"source":["scalar = t.tensor(3.14159) \n","print('scalar: %s, shape of sclar: %s' %(scalar, scalar.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vb5bvUuc24NJ"},"outputs":[],"source":["vector = t.tensor([1, 2])\n","print('vector: %s, shape of vector: %s' %(vector, vector.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jgEbdsPT24NJ"},"outputs":[],"source":["tensor = t.Tensor(1,2) # Note the difference with t.tensor([1, 2])\n","tensor.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16ThLXus24NJ"},"outputs":[],"source":["matrix = t.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n","matrix,matrix.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6vEXRSQt24NJ"},"outputs":[],"source":["t.tensor([[0.11111, 0.222222, 0.3333333]],\n","                     dtype=t.float64,\n","                     device=t.device('cpu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GnIhtovK24NJ"},"outputs":[],"source":["empty_tensor = t.tensor([])\n","empty_tensor.shape"]},{"cell_type":"markdown","metadata":{"id":"J-nF03NU24NK"},"source":["#### <b>Commonly used Tensor operations</b>"]},{"cell_type":"markdown","metadata":{"id":"xEhXd7HE24NK"},"source":["The shape of the tensor can be adjusted by the `tensor.view` method, but the total number of elements before and after adjustment must be consistent. `view` will not modify its own data, and the returned new tensor shares memory with the source tensor, that is, if one of them is changed, the other one will also be changed. In practical applications, it may often be necessary to add or reduce a certain dimension. At this time, the two functions `squeeze` and `unsqueeze` come in handy."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"8GbbgRBU24NK","executionInfo":{"status":"ok","timestamp":1674219528149,"user_tz":-480,"elapsed":5,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"cadce254-8c5c-4678-ee79-475f491cb7e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["a =  tensor([0, 1, 2, 3, 4, 5])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 1, 2],\n","        [3, 4, 5]])"]},"metadata":{},"execution_count":4}],"source":["a = t.arange(0, 6)\n","print(\"a = \", a)\n","a.view(2, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"IFXJmxc_24NK","executionInfo":{"status":"ok","timestamp":1674219715775,"user_tz":-480,"elapsed":457,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"1a5a36be-1765-4313-8f39-616ed28dfef7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 3])"]},"metadata":{},"execution_count":6}],"source":["b = a.view(-1, 3) # When a dimension is -1, its size will be automatically calculated\n","b.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9pd77WGs24NK","executionInfo":{"status":"ok","timestamp":1674219720237,"user_tz":-480,"elapsed":3,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"eaf19b68-4bb2-4640-8da1-80fda0c83479"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 1, 3])"]},"metadata":{},"execution_count":7}],"source":["b.unsqueeze(1) # Pay attention to the shape, add \"1\" to the first dimension (subscript starts from 0)\n","#Equivalent to b[:,None]\n","b[:, None].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1e5ul0Cl24NK","executionInfo":{"status":"ok","timestamp":1674219756832,"user_tz":-480,"elapsed":602,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"1756a461-d31b-4132-d400-41ad58188763"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 3])"]},"metadata":{},"execution_count":9}],"source":["b.unsqueeze(-2) # -2 means the penultimate dimension\n","b.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"jr4kCr-v24NL","executionInfo":{"status":"ok","timestamp":1674196822502,"user_tz":-480,"elapsed":658,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"4bdc98fa-a14b-4b2b-cac1-afc6fd39221e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[0, 1, 2],\n","          [3, 4, 5]]]])"]},"metadata":{},"execution_count":13}],"source":["c = b.view(1, 1, 1, 2, 3)\n","c.squeeze(0) # compress the \"1\" of the 0th dimension"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2F8qflHf24NL","executionInfo":{"status":"ok","timestamp":1674196845925,"user_tz":-480,"elapsed":452,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"47db990c-6de5-4fbd-e02d-a8dc0fd5160f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 1, 2],\n","        [3, 4, 5]])"]},"metadata":{},"execution_count":14}],"source":["c.squeeze() # compress all dimension \"1\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oF60XtqL24NL","executionInfo":{"status":"ok","timestamp":1674196876912,"user_tz":-480,"elapsed":383,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"a8b6697a-be6f-44d6-f740-fb207aac696c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[  0, 100,   2],\n","        [  3,   4,   5]])"]},"metadata":{},"execution_count":15}],"source":["a[1] = 100\n","b # a modification, b as the view, will also be modified"]},{"cell_type":"markdown","metadata":{"id":"NnzTNdOh24NL"},"source":["`resize` is another method that can be used to adjust `size`, but unlike `view`, it can modify the size of the tensor. If the new size exceeds the original size, new memory space will be allocated automatically, and if the new size is smaller than the original size, the previous data will still be saved, see an example."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LmX-8ST24NL","executionInfo":{"status":"ok","timestamp":1674196902580,"user_tz":-480,"elapsed":388,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"b625867b-087f-4433-aaa6-10f4bb05d53d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[  0, 100,   2]])"]},"metadata":{},"execution_count":16}],"source":["b.resize_(1, 3)\n","b"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"Ut3Oo8rQ24NL","executionInfo":{"status":"ok","timestamp":1674196916723,"user_tz":-480,"elapsed":385,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"415ff5a1-1ad0-4384-9231-d59b99c53dac"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[                  0,                 100,                   2],\n","        [                  3,                   4,                   5],\n","        [3180222411935070754, 8391722768137527840, 7959390389040738153]])"]},"metadata":{},"execution_count":17}],"source":["b.resize_(3, 3) # The old data is still saved, and the extra size will allocate new space\n","b"]},{"cell_type":"markdown","metadata":{"id":"1RGf8DL_24NM"},"source":["#### <b>Index operations</b>\n","\n","Tensor supports indexing operations similar to numpy.ndarray, and the syntax is similar. The following uses some examples to explain common indexing operations. Unless otherwise specified, the indexed result shares memory with the original tensor, that is, if one is modified, the other will be modified accordingly."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzPt1x-O24NM","executionInfo":{"status":"ok","timestamp":1674196945826,"user_tz":-480,"elapsed":380,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"5ba7166e-53dc-49eb-e0a6-0730a766d96e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3197,  1.2075, -0.6853, -0.0314],\n","        [-0.1075, -0.6556,  1.3470, -0.6672],\n","        [-1.9355,  0.8121,  0.4140,  1.7275]])"]},"metadata":{},"execution_count":18}],"source":["a = t.randn(3, 4)\n","a"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bpBIMuep24NM","executionInfo":{"status":"ok","timestamp":1674196957065,"user_tz":-480,"elapsed":362,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"7ae75bc2-81e3-4de2-e820-6db01fa76a13"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.3197,  1.2075, -0.6853, -0.0314])"]},"metadata":{},"execution_count":19}],"source":["a[0] # line 0 (subscript starts from 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FqxBJkA24NM","executionInfo":{"status":"ok","timestamp":1674196963996,"user_tz":-480,"elapsed":372,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"65ab8760-0fed-41a8-ca42-8129bc5147d3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.3197, -0.1075, -1.9355])"]},"metadata":{},"execution_count":20}],"source":["a[:, 0] # column 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jhkLCoWS24NM","executionInfo":{"status":"ok","timestamp":1674196967249,"user_tz":-480,"elapsed":6,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"908aa7c0-f595-4091-a12e-81ac2acd5d0b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-0.6853)"]},"metadata":{},"execution_count":21}],"source":["a[0][2] # The second element of row 0, equivalent to a[0, 2]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4KlfieOX24NM","executionInfo":{"status":"ok","timestamp":1674196978374,"user_tz":-480,"elapsed":383,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"dc3bccfa-ec4a-489e-d38e-a0d0c8dc1ac9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-0.0314)"]},"metadata":{},"execution_count":22}],"source":["a[0, -1] # last element of line 0"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"kwEdp8s824NM"},"outputs":[],"source":["a[:2] # The first two rows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ohYSemd24NM"},"outputs":[],"source":["a[:2, 0:2] # The first two rows, columns 0 and 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S2V9Dmvx24NN"},"outputs":[],"source":["print(a[0:1, :2]) # row 0, first two columns\n","print(a[0, :2]) # Note the difference between the two: different shapes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-GjaU0Y-24NN","executionInfo":{"status":"ok","timestamp":1674197007788,"user_tz":-480,"elapsed":350,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"318b0002-959f-4f0f-ccaa-659375d66e83"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3, 4])"]},"metadata":{},"execution_count":23}],"source":["# None is similar to np.newaxis, adding a new axis for a\n","# Equivalent to a.view(1, a.shape[0], a.shape[1])\n","a[None].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2gMMT3V24NN","executionInfo":{"status":"ok","timestamp":1674197014747,"user_tz":-480,"elapsed":363,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"1d8351b9-9a21-490d-b1f2-a8b4fa2c2779"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3, 4])"]},"metadata":{},"execution_count":24}],"source":["a[None].shape # Equivalent to a[None,:,:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iFQrX73k24NN","executionInfo":{"status":"ok","timestamp":1674197031739,"user_tz":-480,"elapsed":547,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"28309ca7-b153-4306-d45a-39d1a25f01b4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 1, 4])"]},"metadata":{},"execution_count":25}],"source":["a[:,None,:].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDdKTHYN24NN","executionInfo":{"status":"ok","timestamp":1674197039363,"user_tz":-480,"elapsed":459,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"88713607-ddb4-4892-a996-6a33c2ebad00"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 1, 4, 1, 1])"]},"metadata":{},"execution_count":26}],"source":["a[:,None,:,None,None].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oy978_qx24NN","executionInfo":{"status":"ok","timestamp":1674197053961,"user_tz":-480,"elapsed":358,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"25c4fffe-c7a5-4d56-87cb-7fc162f591a0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[False,  True, False, False],\n","        [False, False,  True, False],\n","        [False, False, False,  True]])"]},"metadata":{},"execution_count":27}],"source":["a > 1 # return a ByteTensor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2_8dMky24NN","executionInfo":{"status":"ok","timestamp":1674197060576,"user_tz":-480,"elapsed":574,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"87f21924-b56a-4211-b643-dc8af02ec50b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1.2075, 1.3470, 1.7275])"]},"metadata":{},"execution_count":28}],"source":["a[a>1] # equivalent to a.masked_select(a>1)\n","# The selection result does not share the memory space with the original tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"gHBoiSpA24NO","executionInfo":{"status":"ok","timestamp":1674197069998,"user_tz":-480,"elapsed":373,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"a5b88798-e6f2-4d2e-cb47-bbe2cbebc063"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3197,  1.2075, -0.6853, -0.0314],\n","        [-0.1075, -0.6556,  1.3470, -0.6672]])"]},"metadata":{},"execution_count":29}],"source":["a[t.LongTensor([0,1])] # line 0 and line 1"]},{"cell_type":"markdown","metadata":{"id":"iUv-QZDp24NO"},"source":["Other commonly used selection functions are shown in Table.\n","\n","Table 3-2 Commonly used selection functions\n","\n","function|function|\n",":---:|:---:|\n","index_select(input, dim, index) | Select on the specified dimension dim, such as selecting certain rows and certain columns\n","masked_select(input, mask)|Example as above, a[a>0], use ByteTensor to select\n","non_zero(input)|subscript of non-zero elements\n","gather(input, dim, index)|According to index, select data in dim dimension, the output size is the same as index\n","\n","\n","`gather` is a relatively complex operation. For a 2-dimensional tensor, each element of the output is as follows:\n","\n","```python\n","out[i][j] = input[index[i][j]][j] # dim=0\n","out[i][j] = input[i][index[i][j]] # dim=1\n","```\n","The `gather` operation of the 3D tensor is the same. Here are a few examples."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6j4VuEQ24NO","executionInfo":{"status":"ok","timestamp":1674197167487,"user_tz":-480,"elapsed":4,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"3976e4f8-baef-40d0-9190-6d9c3ac909ca"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0,  1,  2,  3],\n","        [ 4,  5,  6,  7],\n","        [ 8,  9, 10, 11],\n","        [12, 13, 14, 15]])"]},"metadata":{},"execution_count":30}],"source":["a = t.arange(0, 16).view(4, 4)\n","a"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yg1QUpvz24NO","executionInfo":{"status":"ok","timestamp":1674197247772,"user_tz":-480,"elapsed":2,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"67f0827b-f30d-49a7-cf2d-65ebc491aac2"},"outputs":[{"output_type":"stream","name":"stdout","text":["index =  tensor([[0, 1, 2, 3]])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0,  5, 10, 15]])"]},"metadata":{},"execution_count":32}],"source":["# Select the elements of the diagonal\n","index = t.LongTensor([[0,1,2,3]])\n","print(\"index = \", index)\n","a.gather(0, index)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-YMam-D24NO","executionInfo":{"status":"ok","timestamp":1674197273329,"user_tz":-480,"elapsed":388,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"936713ed-22f7-4f37-f744-3a60131d56b0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 3],\n","        [ 6],\n","        [ 9],\n","        [12]])"]},"metadata":{},"execution_count":33}],"source":["# Select elements on the anti-diagonal\n","index = t.LongTensor([[3,2,1,0]]).t()\n","a.gather(1, index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pr0W4GSH24NO"},"outputs":[],"source":["# Select the elements on the anti-diagonal, pay attention to the difference from the above\n","index = t.LongTensor([[3,2,1,0]])\n","a.gather(0, index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y1StBHj224NO"},"outputs":[],"source":["# Select elements on two diagonals\n","index = t.LongTensor([[0,1,2,3],[3,2,1,0]]).t()\n","b = a.gather(1, index)\n","b"]},{"cell_type":"markdown","metadata":{"id":"oS6eKr3l24NP"},"source":["The inverse operation corresponding to `gather` is `scatter_`, `gather` fetches the data from the input according to the index, and `scatter_` puts the fetched data back. Note that the `scatter_` function is an inplace operation.\n","\n","```python\n","out = input. gather(dim, index)\n","-->Approximate inverse operation\n","out = Tensor()\n","out.scatter_(dim, index)\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"ONNAukNE24NP"},"outputs":[],"source":["# Put the two diagonal elements back to the specified position\n","c = t.zeros(4,4)\n","c.scatter_(1, index, b.float())"]},{"cell_type":"markdown","metadata":{"id":"1mWMsRvy24NP"},"source":["Any index operation on a tensor is still a tensor. To get the value of a standard python object, you need to call `tensor.item()`. This method is only applicable to tensors containing one element."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IDQ8t1T924NP"},"outputs":[],"source":["a[0,0] #is still tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AEBQakbm24NP"},"outputs":[],"source":["a[0,0].item() # python float"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TDnSutzo24NP"},"outputs":[],"source":["d = a[0:1, 0:1, None]\n","print(d.shape)\n","d.item() # Only a tensor containing one element can call tensor.item, regardless of shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5EGAvuY24NP"},"outputs":[],"source":["# a[0].item()  ->\n","# raise ValueError: only one element tensors can be converted to Python scalars"]},{"cell_type":"markdown","metadata":{"id":"3rlhdKkO24NQ"},"source":["#### Advanced Indexing\n","PyTorch has perfected the index operation in version 0.2, and currently supports most of numpy's advanced indexes [^10]. Advanced indexing can be regarded as an extension of ordinary indexing operations, but the results of advanced indexing operations generally do not share memory with the original Tensor.\n","[^10]: https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#advanced-indexing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJ_x8v1C24NQ"},"outputs":[],"source":["x = t.arange(0,27).view(3,3,3)\n","x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67fMST6G24NQ"},"outputs":[],"source":["x[[1, 2], [1, 2], [2, 0]] # x[1,1,2] and x[2,2,0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I2Vajwf824NQ"},"outputs":[],"source":["x[[2, 1, 0], [0], [1]] # x[2,0,1],x[1,0,1],x[0,0,1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Mq26tLX24NQ"},"outputs":[],"source":["x[[0, 2], ...] # x[0] and x[2]"]},{"cell_type":"markdown","metadata":{"id":"0o6HP0ki24NQ"},"source":["#### Tensor type\n","\n","Tensor has different data types, as shown in Table, each type corresponds to CPU and GPU versions (except HalfTensor). The default tensor is FloatTensor, and the default tensor type can be modified by `t.set_default_tensor_type` (if the default type is GPU tensor, all operations will be performed on the GPU). The type of Tensor is very helpful for analyzing memory usage. For example, for a FloatTensor with a size of (1000, 1000, 1000), it has `1000*1000*1000=10^9` elements, and each element occupies 32bit/8 = 4Byte memory, so it occupies a total of about 4GB memory/video memory . HalfTensor is specially designed for the GPU version. With the same number of elements, the memory usage is only half of that of FloatTensor, so it can greatly alleviate the problem of insufficient GPU memory. However, due to the limited size and precision of the value that HalfTensor can represent[^2], So there may be problems such as overflow.\n","\n","[^2]: https://stackoverflow.com/questions/872544/what-range-of-numbers-can-be-represented-in-a-16-32-and-64-bit-ieee-754-syste\n","\n","Table 3-3: Tensor data types\n","\n","| Data type | dtype | CPU tensor | GPU tensor |\n","| ------------------------ | ------------------------ --------- | ---------------------------------------- -------------------- | ------------------------- |\n","| 32-bit floating point | `torch.float32` or `torch.float` | `torch.FloatTensor` | `torch.cuda.FloatTensor` |\n","| 64-bit floating point | `torch.float64` or `torch.double` | `torch.DoubleTensor` | `torch.cuda.DoubleTensor` |\n","| 16-bit floating point | `torch.float16` or `torch.half` | `torch.HalfTensor` | `torch.cuda.HalfTensor` |\n","| 8-bit integer (unsigned) | `torch.uint8` | [`torch.ByteTensor`](https://pytorch.org/docs/stable/tensors.html#torch.ByteTensor) | `torch.cuda.ByteTensor ` |\n","| 8-bit integer (signed) | `torch.int8` | `torch.CharTensor` | `torch.cuda.CharTensor` |\n","| 16-bit integer (signed) | `torch.int16` or `torch.short` | `torch.ShortTensor` | `torch.cuda.ShortTensor` |\n","| 32-bit integer (signed) | `torch.int32` or `torch.int` | `torch.IntTensor` | `torch.cuda.IntTensor` |\n","| 64-bit integer (signed) | `torch.int64` or `torch.long` | `torch.LongTensor` | `torch.cuda.LongTensor` |\n","\n"," \n","\n","Each data type can be converted to each other. `type(new_type)` is a common method, and there are also shortcut methods such as `float`, `long`, and `half`. The conversion between CPU tensor and GPU tensor is realized by `tensor.cuda` and `tensor.cpu` methods, and `tensor.to(device)` can also be used. Tensor also has a `new` method, which is used in the same way as `t.Tensor`, which will call the constructor of the corresponding type of the tensor to generate a tensor that is consistent with the current tensor type. `torch.*_like(tensora)` can generate a new tensor with the same properties (type, shape, cpu/gpu) as `tensora`. `tensor.new_*(new_shape)` creates a new tensor with a different shape."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gK74GC4Z24NQ"},"outputs":[],"source":["# Set the default tensor, note that the parameter is a string\n","t.set_default_tensor_type('torch.DoubleTensor')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Z_ZFzGQ24NR"},"outputs":[],"source":["a = t.Tensor(2,3)\n","a.dtype # now a is DoubleTensor, dtype is float64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b2JdUFWF24NR"},"outputs":[],"source":["# restore previous default settings\n","t.set_default_tensor_type('torch.FloatTensor')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W3IYgqEa24NR"},"outputs":[],"source":["# Convert a to FloatTensor, equivalent to b=a.type(t.FloatTensor)\n","b = a.float() \n","b.dtype"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"yI7HFFJI24NR"},"outputs":[],"source":["c = a.type_as(b)\n","c"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lk_T_orn24NR"},"outputs":[],"source":["a.new(2,3) # Equivalent to torch.DoubleTensor(2,3), it is recommended to use a.new_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5TsJWjO24NR"},"outputs":[],"source":["t.zeros_like(a) #equivalent to t.zeros(a.shape,dtype=a.dtype,device=a.device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ihegS1bN24NR"},"outputs":[],"source":["t.zeros_like(a, dtype=t.int16) #Some attributes can be modified"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cI_bxhQj24NR"},"outputs":[],"source":["t.rand_like(a)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mr3-nXU624NS"},"outputs":[],"source":["a.new_ones(4,5, dtype=t.int)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTrmyZP924NS"},"outputs":[],"source":["a.new_tensor([3,4]) # "]},{"cell_type":"markdown","metadata":{"id":"O3NOQKN324NS"},"source":["#### Element-by-element operations\n","\n","This part of the operation will operate on each element of the tensor (point-wise, also known as element-wise), and the input and output shapes of such operations are consistent. Commonly used operations are shown in Table 3-4.\n","\n","Table: Common element-wise operations\n","\n","|function|function|\n","|:--:|:--:|\n","|abs/sqrt/div/exp/fmod/log/pow..|absolute value/square root/division/exponent/remainder/exponentiation..|\n","|cos/sin/asin/atan2/cosh..|related trigonometric functions|\n","|ceil/round/floor/trunc| round up/round down/round down/keep only the integer part|\n","|clamp(input, min, max)|Truncated beyond min and max|\n","|sigmod/tanh..|Activation function\n","\n","For many operations, such as div, mul, pow, fmod, etc., PyTorch implements operator overloading, so operators can be used directly. For example, `a ** 2` is equivalent to `torch.pow(a,2)`, and `a * 2` is equivalent to `torch.mul(a,2)`.\n","\n","The output of `clamp(x, min, max)` satisfies the following formula:\n","$$\n","y_i =\n","\\begin{cases}\n","min, & \\text{if } x_i \\lt min \\\\\n","x_i, & \\text{if } min \\le x_i \\le max \\\\\n","max, & \\text{if } x_i \\gt max\\\\\n","\\end{cases}\n","$$\n","`clamp` is often used in some places that need to compare the size, such as taking the larger value of each element of a tensor and another number."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"Hd1VxK5G24NS"},"outputs":[],"source":["a = t.arange(0, 6).view(2, 3).float()\n","t.cos(a)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeFZD1rL24NS"},"outputs":[],"source":["a % 3 # equivalent to t.fmod(a, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"irA3i5mb24NS"},"outputs":[],"source":["a ** 2 ## equivalent to t.pow(a, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JCdMyLyS24NS"},"outputs":[],"source":["# Take each element in a which is larger than 3 (those less than 3 are truncated to 3)\n","print(a)\n","t.clamp(a, min=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vhPVBMLA24NS"},"outputs":[],"source":["b = a.sin_() # The effect is the same as a = a.sin();b=a , but it is more efficient and saves video memory\n","a"]},{"cell_type":"markdown","metadata":{"id":"yw7Z9DYQ24NT"},"source":["#### Merge operation\n","Such operations result in an output shape that is smaller than the input shape, and can perform specified operations along a certain dimension. Such as the addition `sum`, you can calculate the sum of the entire tensor, and you can also calculate the sum of each row or column in the tensor. Common merge operations are shown in Table 3-5.\n","\n","Table: Common merge operations\n","\n","|function|function|\n","|:---:|:---:|\n","|mean/sum/median/mode|mean/sum/median/mode|\n","|norm/dist|norm/distance|\n","|std/var|standard deviation/variance|\n","|cumsum/cumprod|cumulative/cumulative multiplication|\n","\n","Most of the above functions have a parameter **`dim`**, used to specify which dimension these operations are performed on. There are different interpretations of dim (corresponding to axis in Numpy), here is a simple memory method:\n","\n","Suppose the shape of the input is (m, n, k)\n","\n","- If dim=0 is specified, the output shape is (1, n, k) or (n, k)\n","- If dim=1 is specified, the output shape is (m, 1, k) or (m, k)\n","- If dim=2 is specified, the output shape is (m, n, 1) or (m, n)\n","\n","Whether there is \"1\" in size depends on the parameter `keepdim`, `keepdim=True` will keep the dimension `1`. Note that the above is just a summary of experience, not all functions conform to this shape change method, such as `cumsum`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeuFGJNY24NT"},"outputs":[],"source":["b = t.ones(2, 3)\n","b.sum(dim = 0, keepdim=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f-KzYFED24NT"},"outputs":[],"source":["# keepdim=False, do not keep dimension \"1\", pay attention to shape\n","b. sum(dim=0, keepdim=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQ8FtPcF24NT"},"outputs":[],"source":["b.sum(dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"weRfpUqe24NT"},"outputs":[],"source":["a = t.arange(0, 6).view(2, 3)\n","print(a)\n","a.cumsum(dim=1) # accumulate along the row"]},{"cell_type":"markdown","metadata":{"id":"IRzfkWKU24NT"},"source":["#### Compare\n","Some of the comparison functions are element-wise comparisons, which operate like element-wise operations, and others are similar to merge operations. Commonly used comparison functions are shown in Table 3-6.\n","\n","Table: Common comparison functions\n","\n","|function|function|\n","|:--:|:--:|\n","|gt/lt/ge/le/eq/ne|greater than/less than/greater than or equal to/less than or equal to/equal to/not equal|\n","|topk|The largest k number|\n","|sort|sort|\n","|max/min| Compare the maximum and minimum values of two tensors|\n","\n","The comparison operation in the first row of the table has implemented operator overloading, so you can use `a>=b`, `a>b`, `a!=b`, `a==b`, and the return result is a` ByteTensor`, which can be used to select elements. The two operations of max/min are quite special. For max, it has the following three usage situations:\n","- t.max(tensor): returns the largest number in tensor\n","- t.max(tensor,dim): The largest number on the specified dimension, returns tensor and subscript\n","- t.max(tensor1, tensor2): Compare the larger elements of the two tensors\n","\n","As for comparing a tensor with a number, you can use the clamp function. The following example illustrates."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tAa6L5El24NT","executionInfo":{"status":"ok","timestamp":1674198076157,"user_tz":-480,"elapsed":363,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"a2577bb4-6b6d-48bb-b5e8-2da5d005140a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.,  3.,  6.],\n","        [ 9., 12., 15.]])"]},"metadata":{},"execution_count":34}],"source":["a = t.linspace(0, 15, 6).view(2, 3)\n","a"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7DLc-LsJ24NT"},"outputs":[],"source":["b = t.linspace(15, 0, 6).view(2, 3)\n","b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWJBagYf24NU"},"outputs":[],"source":["a>b"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"VAnaL-YS24NU"},"outputs":[],"source":["a[a>b] # a中大于b的元素"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5MeFq4C24NU"},"outputs":[],"source":["t.max(a)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EccFreG324NV"},"outputs":[],"source":["t.max(b, dim=1) \n","# The 15 and 6 of the first return value represent the largest element in row 0 and row 1 respectively\n","# The 0 and 0 of the second return value indicate that the above-mentioned largest number is the 0th element of the line"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"oWZySJ0a24NW"},"outputs":[],"source":["t.max(a,b)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-6wq1ln24NW"},"outputs":[],"source":["# compare a and 10 larger elements\n","t.clamp(a, min=10)"]},{"cell_type":"markdown","metadata":{"id":"3V7BfBZ424NW"},"source":["#### Linear Algebra\n","\n","The linear function of PyTorch mainly encapsulates Blas and Lapack, and its usage and interface are similar to it. Commonly used linear algebra functions are shown in Table 3-7.\n","\n","Table : Commonly used linear algebra functions\n","\n","|function|function|\n","|:---:|:---:|\n","|trace|sum of diagonal elements (trace of matrix)|\n","|diag|diagonal elements|\n","|triu/tril|Matrix upper/lower triangle, offset can be specified|\n","|mm/bmm|Matrix multiplication, batch matrix multiplication|\n","|addmm/addbmm/addmv/addr/badbmm..|Matrix operations\n","|t|transpose|\n","|dot/cross|Inner product/Outer product\n","|inverse| inverse matrix\n","|svd|Singular value decomposition\n","\n","Please refer to the official document [^3] for specific usage instructions. It should be noted that the transposition of the matrix will cause the storage space to be discontinuous, and its `.contiguous` method needs to be called to convert it to continuous.\n","[^3]: http://pytorch.org/docs/torch.html#blas-and-lapack-operations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5uZyx4_724NW","executionInfo":{"status":"ok","timestamp":1674198133297,"user_tz":-480,"elapsed":4,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"d1d9d008-0188-4f02-98d6-51391acc0cde"},"outputs":[{"output_type":"stream","name":"stdout","text":["b =  tensor([[ 0.,  9.],\n","        [ 3., 12.],\n","        [ 6., 15.]])\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":37}],"source":["b = a.t()\n","print(\"b = \", b)\n","b.is_contiguous()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65NKx6G524NW","executionInfo":{"status":"ok","timestamp":1674198090159,"user_tz":-480,"elapsed":712,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"b98bde41-208d-4469-895a-78a7b9aa7488"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.,  9.],\n","        [ 3., 12.],\n","        [ 6., 15.]])"]},"metadata":{},"execution_count":36}],"source":["b.contiguous()"]},{"cell_type":"markdown","metadata":{"id":"LkJrZIem24NW"},"source":["### 3.1.2 Tensor and Numpy\n","\n","There is a high similarity between Tensor and Numpy arrays, and the interoperation between them is also very simple and efficient. It should be noted that Numpy and Tensor share memory. Since Numpy has a long history and supports rich operations, when encountering an operation that Tensor does not support, it can be converted into a Numpy array first, and then converted back to tensor after processing, and the conversion cost is very small."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QiGWl28F24NW"},"outputs":[],"source":["import numpy as np\n","a = np.ones([2, 3],dtype=np.float32)\n","a"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TmUyZIxr24NX"},"outputs":[],"source":["b = t.from_numpy(a)\n","b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OkZC_S3v24NX"},"outputs":[],"source":["b = t.Tensor(a) # You can also directly pass numpy objects into Tensor\n","b"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"uJLuAvcp24NX"},"outputs":[],"source":["a[0, 1]=100\n","b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_zYYaRlf24NX"},"outputs":[],"source":["c = b.numpy() # a, b, c three objects share memory\n","c"]},{"cell_type":"markdown","metadata":{"id":"UrYxTXeW24NX"},"source":["**Note**: When the data type of numpy is different from the type of Tensor, the data will be copied and memory will not be shared."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szNX-VNh24NX"},"outputs":[],"source":["a = np.ones([2, 3])\n","# Note the difference from a above (dtype is not float32)\n","a.dtype"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOA4HUue24NX"},"outputs":[],"source":["b = t.Tensor(a) # Copy here, no shared memory\n","b.dtype"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3eX1MHFG24NY"},"outputs":[],"source":["c = t.from_numpy(a) # Note the type of c (DoubleTensor)\n","c"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8PIO1EXn24NY"},"outputs":[],"source":["a[0, 1] = 100\n","b # b and a do not share memory, so even if a changes, b will not change"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"skinYgjI24NY"},"outputs":[],"source":["c # c shares memory with a"]},{"cell_type":"markdown","metadata":{"id":"eAS8WYlT24NY"},"source":["**Note:** Regardless of the input type, t.tensor will copy data and will not share memory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jqbpZk-m24NY"},"outputs":[],"source":["tensor = t.tensor(a) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l6Lvy7pM24NY"},"outputs":[],"source":["tensor[0,0]=0\n","a"]},{"cell_type":"markdown","metadata":{"id":"QLMZT4Jg24NY"},"source":["Broadcasting is a trick often used in scientific computing to perform vectorization quickly without taking up extra memory/video memory.\n","Numpy's broadcasting law is defined as follows:\n","\n","- Let all the input arrays align with the array with the longest shape, and the insufficient part of the shape is filled by adding 1 in front\n","- The two arrays either have the same length in a certain dimension, or one of them is 1, otherwise it cannot be calculated\n","- When the length of a certain dimension of the input array is 1, copy and expand along this dimension to the same shape during calculation\n","\n","PyTorch currently supports the automatic broadcasting rule, but the author still recommends readers to manually implement the broadcasting rule through the combination of the following two functions, which is more intuitive and less error-prone:\n","\n","- `unsqueeze` or `view`, or tensor[None],: add 1 to the shape of a certain dimension of the data, and implement rule 1\n","- `expand` or `expand_as`, repeating the array, implements rule 3; this operation does not copy the array, so it does not take up extra space.\n","\n","Note that repeat implements a similar function to expand, but repeat will make multiple copies of the same data, so it will take up additional space."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"V_0kJdx824NY"},"outputs":[],"source":["a = t.ones(3, 2)\n","b = t.zeros(2, 3,1)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"qQdI5xzw24NY"},"outputs":[],"source":["# Automatic broadcast rules\n","# The first step: a is 2-dimensional, b is 3-dimensional, so add 1 in front of the smaller a,\n","# That is: a.unsqueeze(0), the shape of a becomes (1, 3, 2), the shape of b is (2, 3, 1),\n","# The second step: a and b have different shapes in the first and third dimensions, one of which is 1,\n","# Can be extended by broadcasting law, both shapes become (2, 3, 2)\n","\n","a+b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9DfYOTs-24NZ"},"outputs":[],"source":["# Manual broadcast rules\n","# or a.view(1,3,2).expand(2,3,2)+b.expand(2,3,2)\n","a[None].expand(2, 3, 2) + b.expand(2,3,2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k-qhw8r424NZ"},"outputs":[],"source":["# expand will not take up extra space, it will only be expanded when needed, which can greatly save memory\n","e = a.unsqueeze(0).expand(10000000000000, 3,2)"]},{"cell_type":"markdown","metadata":{"id":"8AIX3NQq24NZ"},"source":["### Internal structure\n","\n","The data structure of tensor is shown in below Figure. The tensor is divided into a header information area (Tensor) and a storage area (Storage). The information area mainly stores information such as the shape (size), stride (stride), and data type (type) of the tensor, while the real data is stored as a continuous array. Since the data is often tens of thousands, the elements in the information area occupy less memory, and the main memory occupation depends on the number of elements in the tensor, that is, the size of the storage area.\n","\n","Generally speaking, a tensor has a corresponding storage, and storage is an interface encapsulated on top of data, which is easy to use, and the header information of different tensors is generally different, but they may use the same data. Let's look at two examples.\n","\n","![Figure 3-1: Tensor data structure](https://drive.google.com/uc?export=view&id=11TaXMk35yfdehqMMbI9TO1vOuuGWw-FB)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pnO0U1oz24NZ","executionInfo":{"status":"ok","timestamp":1674198167877,"user_tz":-480,"elapsed":360,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"cfb8cefd-9971-4f95-efd2-9d1a8e999b1a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":[" 0\n"," 1\n"," 2\n"," 3\n"," 4\n"," 5\n","[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]"]},"metadata":{},"execution_count":38}],"source":["a = t.arange(0, 6)\n","a.storage()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kx2dWVQt24NZ"},"outputs":[],"source":["b = a.view(2, 3)\n","b.storage()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EYAWRuVL24NZ"},"outputs":[],"source":["# The id value of an object can be seen as its address in memory\n","# The memory address of storage is the same, that is, the same storage\n","id(b.storage()) == id(a.storage())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VrqUj1_i24NZ"},"outputs":[],"source":["# a changes, b also changes, because they share storage\n","a[1] = 100\n","b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1IhBAtX24NZ"},"outputs":[],"source":["c = a[2:] \n","c.storage()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTtZX-ei24Na"},"outputs":[],"source":["c.data_ptr(), a.data_ptr() # data_ptr returns the memory address of the first element of tensor\n","# It can be seen that the difference is 8, this is because 2*4=8--the difference is two elements, each element occupies 4 bytes (float)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVIEQ9a624Na"},"outputs":[],"source":["c[0] = -100 # The memory address of c[0] corresponds to the memory address of a[2]\n","a"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxr-b86R24Na"},"outputs":[],"source":["d = t.LongTensor(c.storage())\n","d[0] = 6666\n","b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTvVDFX424Na"},"outputs":[],"source":["# The following four tensor share storage\n","id(a.storage()) == id(b.storage()) == id(c.storage()) == id(d.storage())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohWoR61d24Na"},"outputs":[],"source":["a.storage_offset(), c.storage_offset(), d.storage_offset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z6h044-L24Na"},"outputs":[],"source":["e = b[::2, ::2] # Take an element every 2 rows/columns\n","id(e.storage()) == id(a.storage())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kwi-G2Gr24Na"},"outputs":[],"source":["b.stride(), e.stride()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M_qMv2qL24Na"},"outputs":[],"source":["e.is_contiguous()"]},{"cell_type":"markdown","metadata":{"id":"rVJtzNJ_24Na"},"source":["It can be seen that most operations do not modify the data of the tensor, but only modify the header information of the tensor. This approach saves memory and improves processing speed. Need to pay attention in use.\n","In addition, some operations will cause the tensor to be discontinuous. In this case, you need to call the `tensor.contiguous` method to turn them into continuous data. This method will make a copy of the data and no longer share storage with the original data.\n","In addition, readers can think about it. The advanced index mentioned before generally does not share stroage, while the common index shares storage. Why? (Hint: Ordinary indexing can be implemented by only modifying the offset, stride and size of the tensor, without modifying the storage)."]},{"cell_type":"markdown","metadata":{"id":"pcOKu3xF24Na"},"source":["### Other topics about Tensor\n","It is not easy to divide the content of this part into a special section, but it is still worthy of readers' attention, so I put it in this section."]},{"cell_type":"markdown","metadata":{"id":"jDE-atGS24Nb"},"source":["####GPU/CPU\n","Tensor can be transmitted on gpu/cpu at will. Use `tensor.cuda(device_id)` or `tensor.cpu()`. Another more general method is `tensor.to(device)`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n41hN6ek24Nb","executionInfo":{"status":"ok","timestamp":1674220020152,"user_tz":-480,"elapsed":464,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"52d8b208-3ea2-417f-c79f-0ab37aaba47b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":10}],"source":["a = t.randn(3, 4)\n","a.device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xb8HlC0Z24Nb"},"outputs":[],"source":["if t.cuda.is_available():\n","    a = t.randn(3,4, device=t.device('cuda'))\n","     # Equivalent to\n","     # a.t.randn(3,4).cuda(1)\n","     # but the former is faster\n","    a.device"]},{"cell_type":"code","source":["a.device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43yjAE1MDa4c","executionInfo":{"status":"ok","timestamp":1674220111512,"user_tz":-480,"elapsed":500,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"af7b05d5-a5e4-4cdb-a679-ff0dcfaaa202"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zsa419_V24Nb","executionInfo":{"status":"ok","timestamp":1674199352311,"user_tz":-480,"elapsed":362,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"b378c422-0576-4d87-b238-4a9bf6b08134"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.5317,  0.3929,  0.7880, -0.3658],\n","        [-1.7484, -1.7635,  1.1531, -1.5416],\n","        [ 0.8710, -0.6144,  0.2610, -1.0538]])"]},"metadata":{},"execution_count":9}],"source":["device = t.device('cpu')\n","a.to(device)"]},{"cell_type":"markdown","metadata":{"id":"5sLaeV-I24Nb"},"source":["**Notice**\n","- Try to use `tensor.to(device)`, set `device` as a configurable parameter, so that you can easily make the program compatible with both GPU and CPU\n","- The speed of data transfer in GPU is much faster than that from memory (CPU) to video memory (GPU), so try to avoid frequent data transfer between memory and video memory."]},{"cell_type":"markdown","metadata":{"id":"Vkj7PJGg24Nb"},"source":["#### Persistence\n","The saving and loading of Tensor is very simple, use t.save and t.load to complete corresponding function. The `pickle` module can be specified when saving/loading, and the GPU tensor can be mapped to the CPU or other GPUs when loading."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"OCHVjX_z24Nb"},"outputs":[],"source":["if t.cuda.is_available():\n","    a = a.cuda(1) # Convert a to tensor on GPU1,\n","    t.save(a,'a.pth')\n","\n","    # Load as b, store on GPU1 (because tensor is on GPU1 when saving)\n","    b = t.load('a.pth')\n","    # load as c, store in CPU\n","    c = t.load('a.pth', map_location=lambda storage, loc: storage)\n","    # loaded as d, stored on GPU0\n","    d = t.load('a.pth', map_location={'cuda:1':'cuda:0'})"]},{"cell_type":"markdown","metadata":{"id":"RduvOpNK24Nb"},"source":["#### Vectorization"]},{"cell_type":"markdown","metadata":{"id":"Qfhw3qOh24Nb"},"source":["Vectorized computing is a special parallel computing method. Compared with the general program that only performs one operation at the same time, it can perform multiple operations at the same time, usually executing the same one or a batch of instructions on different data. , or apply the instruction to an array/vector. Vectorization can greatly improve the efficiency of scientific operations. Python itself is a high-level language that is easy to use, but it also means that many operations are very inefficient, especially the `for` loop. Python's native `for loop' should be avoided as much as possible in scientific computing programs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oh3DEduu24Nb"},"outputs":[],"source":["def for_loop_add(x, y):\n","    result = []\n","    for i,j in zip(x, y):\n","        result.append(i + j)\n","    return t.Tensor(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"SNdSAiMH24Nc"},"outputs":[],"source":["x = t.zeros(100)\n","y = t.ones(100)\n","%timeit -n 10 for_loop_add(x, y)\n","%timeit -n 10 x + y"]},{"cell_type":"markdown","metadata":{"id":"C6cx803-24Nc"},"source":["It can be seen that there is a speed gap of more than dozens of times between the two, so in actual use, you should try to call the builtin-function (buildin-function). The underlying functions of these functions are implemented by C/C++, and can achieve efficient calculations by performing underlying optimization. Therefore, when writing code, you should develop the habit of thinking in vectorization, and avoid element-by-element traversal of larger tensors."]},{"cell_type":"markdown","metadata":{"id":"p7PnoTfF24Nc"},"source":["In addition, there are the following points to note:\n","- Most `t.function` has a parameter `out`, and the result generated at this time will be saved in the tensor specified by out.\n","- `t.set_num_threads` can set the number of threads occupied by PyTorch for CPU multi-threaded parallel computing, which can be used to limit the number of CPUs occupied by PyTorch.\n","- `t.set_printoptions` can be used to set the numerical precision and format when printing tensor.\n","The following example illustrates."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDAAYeTR24Nc"},"outputs":[],"source":["a = t.arange(0, 20000000)\n","print(a[-1], a[-2]) # 32bit IntTensor has limited precision, resulting in overflow\n","b = t.LongTensor()\n","t.arange(0, 20000000, out=b) # 64bit LongTensor will not overflow\n","b[-1], b[-2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_Rt83C224Nc"},"outputs":[],"source":["a = t.randn(2,3)\n","a"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"FNhlfnA024Nc"},"outputs":[],"source":["t.set_printoptions(precision=10)\n","a"]},{"cell_type":"markdown","metadata":{"id":"H8JI2ynK24Nc"},"source":["###  Small test: linear regression"]},{"cell_type":"markdown","metadata":{"id":"G4oxGfvt24Nc"},"source":["Linear regression is an introductory knowledge of machine learning and has a wide range of applications. Linear regression uses regression analysis in mathematical statistics to determine the quantitative relationship between two or more variables. Its expression is $y = wx+b+e$, and $e$ is the error subject to the mean value of 0 normal distribution. First let's confirm the loss function of linear regression:\n","$$\n","loss = \\sum_i^N \\frac 1 2 ({y_i-(wx_i+b)})^2\n","$$\n","Then use the stochastic gradient descent method to update the parameters $\\textbf{w}$ and $\\textbf{b}$ to minimize the loss function, and finally learn the values ​​of $\\textbf{w}$ and $\\textbf{b}$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rD8kVoNl24Nd"},"outputs":[],"source":["import torch as t\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","from IPython import display\n","\n","device = t.device('cuda:0') #If you want to use gpu, change to t.device('cuda:0')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wo1zBNR524Nd"},"outputs":[],"source":["# Set the random number seed to ensure that the following output is consistent when running on different computers\n","t.manual_seed(1000) \n","\n","def get_fake_data(batch_size=8):\n","    ''' Generate random data: y=x*2+3, plus some noise'''\n","    x = t.rand(batch_size, 1, device=device) * 5\n","    y = x * 2 + 3 +  t.randn(batch_size, 1, device=device)\n","    return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"rJm-m2GD24Nd","executionInfo":{"status":"ok","timestamp":1674220466079,"user_tz":-480,"elapsed":473,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"8e2a76ea-3941-4c3a-bb93-8ba4e2536b22"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PathCollection at 0x7ff4a7195c70>"]},"metadata":{},"execution_count":16},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMP0lEQVR4nO3dX2yddR3H8c/HbYYDosWsIVsRy4XpDSAlDVExaPhjUYk0xERIMBBJdmMUNCmyeEG8EZIag4mJZhFEI0ETKNNotCyAIRj+2LFBB6NyIeA6cCVYFWzCmF8vdjq62tOenvOcPs935/1KlrZP/5xvnov3Tn7n+T3HESEAQD7vKXsAAEBrCDgAJEXAASApAg4ASRFwAEhq43o+2ObNm6O/v389HxIA0tu9e/frEdG79Pi6Bry/v1+Tk5Pr+ZAAkJ7tl5c7zhIKACRFwAEgKQIOAEkRcABIioADQFLrehUKALRr554ZjU1M6+DcvLb21DQ6PKCRwb6yxyoFAQeQxs49M9o+PqX5w0ckSTNz89o+PiVJXRlxllAApDE2MX0s3gvmDx/R2MR0SROVi4ADSOPg3Pyajp/oCDiANLb21NZ0/ERHwAGkMTo8oNqmDccdq23aoNHhgZImKhcvYgJIY+GFSq5COYqAA0hlZLCva4O9FEsoAJAUAQeApAg4ACTFGjgAdFAnt/4TcADokE5v/WcJBQA6pNNb/wk4AHRIp7f+E3AA6JBOb/0n4ADQIZ3e+s+LmADQIZ3e+k/AAaCDOrn1nyUUAEiKgANAUgQcAJIi4ACQFAEHgKQIOAAkRcABICkCDgBJEXAASIqAA0BSBBwAkiLgAJDUqgG3fZftQ7b3LTo2ZvsF28/afsB2T2fHBAAs1cwz8LslXb7k2C5JZ0fEuZL+Iml7wXMBAFaxasAj4lFJbyw59mBEvFP/8glJZ3RgNgDACopYA/+KpN83+qbtbbYnbU/Ozs4W8HAAAKnNgNv+tqR3JN3T6GciYkdEDEXEUG9vbzsPBwBYpOV35LF9vaQrJF0SEVHYRACAprQUcNuXS7pZ0qci4j/FjgQAaEYzlxHeK+lxSQO2D9i+QdIPJZ0qaZftvbZ/3OE5AQBLrPoMPCKuWebwnR2YBQCwBuzEBICkCDgAJEXAASApAg4ASRFwAEiKgANAUgQcAJIi4ACQFAEHgKQIOAAkRcABICkCDgBJEXAASIqAA0BSBBwAkiLgAJAUAQeApAg4ACRFwAEgKQIOAEkRcABIioADQFIEHACSIuAAkNTGsgcA0Lyde2Y0NjGtg3Pz2tpT0+jwgEYG+8oeCyUh4EASO/fMaPv4lOYPH5EkzczNa/v4lCQR8S7FEgqQxNjE9LF4L5g/fERjE9MlTYSyEXAgiYNz82s6jhMfAQeS2NpTW9NxnPgIOJDE6PCAaps2HHestmmDRocHSpoIZeNFTCCJhRcquQoFCwg4ULBOXuo3MthHsHEMAQcKxKV+WE+sgQMF4lI/rCcCDhSIS/2wngg4UCAu9cN6WjXgtu+yfcj2vkXHPmh7l+0X6x9P6+yYQA5c6of11Mwz8LslXb7k2C2SHoqIj0h6qP410PVGBvt021XnqK+nJkvq66nptqvO4QVMdMSqV6FExKO2+5ccvlLSp+uf/0zSHyV9q8C5gLS41A/rpdU18NMj4tX6569JOr3RD9reZnvS9uTs7GyLDwcAWKrtFzEjIiTFCt/fERFDETHU29vb7sMBAOpaDfjfbW+RpPrHQ8WNBABoRqsB/42k6+qfXyfp18WMAwBoVjOXEd4r6XFJA7YP2L5B0u2SLrP9oqRL618DANZRM1ehXNPgW5cUPAsAYA3YiQkASRFwAEiKgANAUgQcAJIi4ACQFAEHgKQIOAAkRcABICkCDgBJEXAASIqAA0BSBBwAkiLgAJAUAQeApAg4ACRFwAEgKQIOAEkRcABIioADQFIEHACSIuAAkBQBB4CkCDgAJEXAASApAg4ASRFwAEiKgANAUgQcAJIi4ACQFAEHgKQIOAAkRcABICkCDgBJEXAASIqAA0BSBBwAkmor4La/Yfs52/ts32v7pKIGAwCsrOWA2+6T9HVJQxFxtqQNkq4uajAAwMraXULZKKlme6OkkyUdbH8kAEAzWg54RMxI+p6kVyS9KumfEfFgUYMBAFbWzhLKaZKulHSWpK2STrF97TI/t832pO3J2dnZ1icFABynnSWUSyX9NSJmI+KwpHFJn1j6QxGxIyKGImKot7e3jYcDACzWTsBfkfQx2yfbtqRLJO0vZiwAwGraWQN/UtJ9kp6WNFX/WzsKmgsAsIqN7fxyRNwq6daCZgEArAE7MQEgKQIOAEkRcABIioADQFIEHACSIuAAkBQBB4CkCDgAJEXAASApAg4ASRFwAEiKgANAUgQcAJIi4ACQFAEHgKQIOAAkRcABICkCDgBJEXAASIqAA0BSBBwAkiLgAJAUAQeApAg4ACRFwAEgKQIOAEkRcABIioADQFIbyx4AWGznnhmNTUzr4Ny8tvbUNDo8oJHBvrLHAiqJgKMydu6Z0fbxKc0fPiJJmpmb1/bxKUki4sAyWEJBZYxNTB+L94L5w0c0NjFd0kRAtRFwVMbBufk1HQe6HQFHZWztqa3pONDtCDgqY3R4QLVNG447Vtu0QaPDAyVNBFQbL2KiMhZeqOQqFKA5BByVMjLYR7CBJrGEAgBJtRVw2z2277P9gu39tj9e1GAAgJW1u4TyA0l/iIgv2n6vpJMLmAkA0ISWA277A5IuknS9JEXE25LeLmas7sQ2cgBr0c4z8LMkzUr6qe2PStot6caIeGvxD9neJmmbJJ155pltPFwua40x28gBrFU7a+AbJZ0v6UcRMSjpLUm3LP2hiNgREUMRMdTb29vGw+WxEOOZuXmF3o3xzj0zDX+n0Tbym361Vxfe/vCKvwugO7UT8AOSDkTEk/Wv79PRoHe9Vu7psdJ28Wb+AwDQfVoOeES8Julvthe2yV0i6flCpkqulXt6rLZdnJs6AViq3evAvybpHtvPSjpP0nfbHym/Vu7psdw28qW4qROAxdoKeETsra9vnxsRIxHxj6IGy6yVe3qMDPbptqvOUd8KkeemTgAWYydmByyOsSX19dR021XnrHo1ychgn/50y8W640vncVMnAKviXigd0s49PbipE4BmEPCK4qZOAFbDEgoAJEXAASApAg4ASRFwAEiKgANAUgQcAJIi4ACQFAEHgKQIOAAklWInJm81BgD/r/IB563GAGB5lV9CaeXdbQCgG1Q+4K28uw0AdIPKB7yVd7cBgG5Q+YC38u42ANANKv8iJm9uAADLq3zAJd7cAACWU/klFADA8gg4ACRV+SUUdmECwPIqHXB2YQJAY5VeQmEXJgA0VumAswsTABqrdMDZhQkAjVU64OzCBIDGKv0iJrswAaCxSgdcYhcmADRS6SUUAEBjBBwAkiLgAJAUAQeApAg4ACTliFi/B7NnJb28bg/Y2GZJr5c9RIVxfhrj3DTGuVlZO+fnwxHRu/Tguga8KmxPRsRQ2XNUFeenMc5NY5yblXXi/LCEAgBJEXAASKpbA76j7AEqjvPTGOemMc7Nygo/P125Bg4AJ4JufQYOAOkRcABIqqsCbvsu24ds7yt7lqqx/SHbj9h+3vZztm8se6YqsX2S7adsP1M/P98pe6aqsb3B9h7bvy17liqx/ZLtKdt7bU8W+re7aQ3c9kWS3pT084g4u+x5qsT2FklbIuJp26dK2i1pJCKeL3m0SrBtSadExJu2N0l6TNKNEfFEyaNVhu1vShqS9P6IuKLsearC9kuShiKi8E1OXfUMPCIelfRG2XNUUUS8GhFP1z//t6T9krgRe10c9Wb9y031f93z7GcVts+Q9HlJPyl7lm7SVQFHc2z3SxqU9GS5k1RLfYlgr6RDknZFBOfnXXdIulnSf8sepIJC0oO2d9veVuQfJuA4ju33Sbpf0k0R8a+y56mSiDgSEedJOkPSBbZZhpNk+wpJhyJid9mzVNQnI+J8SZ+V9NX6Um4hCDiOqa/t3i/pnogYL3ueqoqIOUmPSLq87Fkq4kJJX6iv9f5S0sW2f1HuSNURETP1j4ckPSDpgqL+NgGHpGMv0t0paX9EfL/searGdq/tnvrnNUmXSXqh3KmqISK2R8QZEdEv6WpJD0fEtSWPVQm2T6lfFCDbp0j6jKTCroLrqoDbvlfS45IGbB+wfUPZM1XIhZK+rKPPnvbW/32u7KEqZIukR2w/K+nPOroGzuVyWM3pkh6z/YykpyT9LiL+UNQf76rLCAHgRNJVz8AB4ERCwAEgKQIOAEkRcABIioADQFIEHACSIuAAkNT/AD9ZoiGs+ZJqAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}],"source":["# Let's see the resulting x-y distribution\n","x, y = get_fake_data(batch_size=10)\n","plt.scatter(x.squeeze().cpu().numpy(), y.squeeze().cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"GnPZnnWa24Nd","executionInfo":{"status":"ok","timestamp":1674220751268,"user_tz":-480,"elapsed":12175,"user":{"displayName":"Paul Yuan","userId":"03854332779400707023"}},"outputId":"2679c842-2437-482b-b405-28a3110ae5fd"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["w:  1.906325340270996 b:  2.937190532684326\n"]}],"source":["# random initialization parameters\n","w = t.rand(1, 1).to(device)\n","b = t.zeros(1, 1).to(device)\n","\n","lr =0.02 # learning rate\n","\n","for ii in range(1000):\n","    x, y = get_fake_data(batch_size=4)\n","    \n","    # forward：calculate loss\n","    y_pred = x.mm(w) + b.expand_as(y) # x@W is equivalent to x.mm(w); for python3 only\n","    loss = 0.5 * (y_pred - y) ** 2 # mean square error\n","    loss = loss.mean()\n","    \n","    # backward：manually calculate the gradient\n","    dloss = 1\n","    dy_pred = dloss * (y_pred - y)\n","    \n","    dw = x.t().mm(dy_pred)\n","    db = dy_pred.sum()\n","    \n","    # Update parameters\n","    w.sub_(lr * dw)\n","    b.sub_(lr * db)\n","    \n","    if ii%50 ==0:\n","       \n","        # drawing\n","        display.clear_output(wait=True)\n","        x = t.arange(0, 6, device = device).view(-1, 1)\n","        y = x.float().mm(w) + b.expand_as(x)\n","        plt.plot(x.cpu().numpy(), y.cpu().numpy()) # predicted\n","        \n","        x2, y2 = get_fake_data(batch_size=32) \n","        plt.scatter(x2.cpu().numpy(), y2.cpu().numpy()) # true data\n","        \n","        plt.xlim(0, 5)\n","        plt.ylim(0, 13)\n","        plt.show()\n","        plt.pause(0.5)\n","        \n","print('w: ', w.item(), 'b: ', b.item())"]},{"cell_type":"markdown","metadata":{"id":"gTXN2rVt24Nd"},"source":["It can be seen that the program has basically learned w=2 and b=3, and the straight line and data in the figure have achieved a good fit.\n","\n","Although there are many operations mentioned above, as long as you master this example, you can basically do it. For other knowledge, when readers encounter it in the future, they can look at the content of this part or find the corresponding documents."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gm9DyopS24Nd"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}