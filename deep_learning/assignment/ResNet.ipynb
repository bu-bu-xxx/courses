{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mLX73hWKhbAS"
      },
      "outputs": [],
      "source": [
        "# Import some necessary library\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "snmWu0a4h4iT"
      },
      "outputs": [],
      "source": [
        "# Build the 18-layer ResNet model\n",
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += self.shortcut(residual)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 , num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        out = self.avg_pool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def resnet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PIIiYQwBiPzx"
      },
      "outputs": [],
      "source": [
        "# Initialize two ResNet 18 models\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_SGD = resnet18().to(device)\n",
        "model_ADAM = resnet18().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw0gC3mZiefd",
        "outputId": "c544395f-6bb8-4207-d93d-fe83b56dd699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR 10 Datasets\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=1)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "39HY9WkTjLDE"
      },
      "outputs": [],
      "source": [
        "# Train function\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    train_loss, correct = 0, 0\n",
        "    model.train()\n",
        "    for X, y in tqdm.tqdm(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        train_loss += loss.item()\n",
        "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Avg Train loss: {loss:>8f} \\n\")\n",
        "    return train_loss, correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gu341tM1jSqS"
      },
      "outputs": [],
      "source": [
        "# Test function\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss, correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Tg4hn1Isjhvj"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the loss function \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# set the optimizer as SGD with Momentum \n",
        "# Please finish this part\n",
        "optimizer_SGD = optim.SGD(model_SGD.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzhKFLsSjjaB"
      },
      "outputs": [],
      "source": [
        "# Train model_SGD by SGD with Momentum optimization algorith\n",
        "# Please add code to finish this part.\n",
        "train_loss_SGD, train_acc_SGD = [], []\n",
        "test_loss_SGD, test_acc_SGD = [], []\n",
        "\n",
        "for epoch in range(30):\n",
        "    train_loss, train_acc = train(trainloader, model_SGD, criterion, optimizer_SGD)\n",
        "    train_loss_SGD.append(train_loss)\n",
        "    train_acc_SGD.append(train_acc)\n",
        "    test_loss, test_acc = test(testloader, model_SGD, criterion)\n",
        "    test_loss_SGD.append(test_loss)\n",
        "    test_acc_SGD.append(test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Repeat the training and testing procedure for model_ADAM\n",
        "# Visualize the results and save the images. Add the images to your assignment solution.\n",
        "optimizer_ADAM = optim.Adam(model_ADAM.parameters(), lr=0.01)\n",
        "\n",
        "train_loss_ADAM, train_acc_ADAM = [], []\n",
        "test_loss_ADAM, test_acc_ADAM = [], []\n",
        "\n",
        "for epoch in range(30):\n",
        "    train_loss, train_acc = train(trainloader, model_ADAM, criterion, optimizer_ADAM)\n",
        "    train_loss_ADAM.append(train_loss)\n",
        "    train_acc_ADAM.append(train_acc)\n",
        "    test_loss, test_acc = test(testloader, model_ADAM, criterion)\n",
        "    test_loss_ADAM.append(test_loss)\n",
        "    test_acc_ADAM.append(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzAWnvxTj2QL"
      },
      "outputs": [],
      "source": [
        "# Visualize the results (You can refer to other tutorial notebooks)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Add codes to finish this part and save the images. Add the images to your assignment solution.\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(train_loss_SGD, label='Train Loss SGD')\n",
        "plt.plot(train_loss_ADAM, label='Train Loss ADAM')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Train Loss vs Epochs')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(test_loss_SGD, label='Test Loss SGD')\n",
        "plt.plot(test_loss_ADAM, label='Test Loss ADAM')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Test Loss vs Epochs')\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(train_acc_SGD, label='Train Accuracy SGD')\n",
        "plt.plot(train_acc_ADAM, label='Train Accuracy ADAM')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Train Accuracy vs Epochs')\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(test_acc_SGD, label='Test Accuracy SGD')\n",
        "plt.plot(test_acc_ADAM, label='Test Accuracy ADAM')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Test Accuracy vs Epochs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
