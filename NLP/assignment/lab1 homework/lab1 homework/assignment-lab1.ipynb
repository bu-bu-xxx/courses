{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we finetune the bert model and add a classification layer after last_hidden_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from tsv files\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "train_file = os.path.join(data_dir, 'train.tsv')\n",
    "test_file = os.path.join(data_dir, 'test.tsv')\n",
    "\n",
    "train_data = pd.read_csv(train_file, sep='\\t', keep_default_na=False)\n",
    "test_data = pd.read_csv(test_file, sep='\\t', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 56)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length of each phrase tokens\n",
    "train_data['Phrase'].apply(lambda x: len(x.split())).max(), \\\n",
    "    test_data['Phrase'].apply(lambda x: len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FinetuneDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=60):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.loc[idx, 'Phrase']\n",
    "        label = self.data.loc[idx, 'Sentiment']\n",
    "\n",
    "        inputs = self.tokenizer(text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
    "        input_ids = inputs['input_ids'].squeeze()\n",
    "        attention_mask = inputs['attention_mask'].squeeze()\n",
    "\n",
    "        return input_ids, attention_mask, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download bert model\n",
    "dir = os.path.join(os.getcwd(), \"models\")\n",
    "bert_base_model = \"bert-base-uncased\"\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(\n",
    "    bert_base_model, cache_dir=dir\n",
    ")\n",
    "bert_model = transformers.BertModel.from_pretrained(\n",
    "    bert_base_model, cache_dir=dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a classification layer after the bert model\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask)\n",
    "        last_hidden_state = outputs[0]\n",
    "        cls_output = last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(cls_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training method\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(model, train_loader, test_loader, optimizer, criterion, device, epoch_num=2,\n",
    "          test_only=False):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(epoch_num):\n",
    "        total_loss = 0\n",
    "        for input_ids, attention_mask, labels in tqdm(train_loader):\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy = accuracy_score(labels.cpu(), logits.argmax(dim=1).cpu())\n",
    "        print(f'Epoch {epoch + 1}/{epoch_num}, Loss: {total_loss:.4f}')\n",
    "        print(f'Training Accuracy: {total_accuracy:.4f}')\n",
    "        # evaluate on the validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_accuracy = 0\n",
    "            for input_ids, attention_mask, labels in tqdm(test_loader):\n",
    "                input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "                logits = model(input_ids, attention_mask)\n",
    "                total_accuracy += accuracy_score(labels.cpu(), logits.argmax(dim=1).cpu())\n",
    "            print(f'Validation Accuracy: {total_accuracy/len(test_loader):.4f}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train_data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainset_data, testset_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "trainset_data = trainset_data.reset_index(drop=True)\n",
    "testset_data = testset_data.reset_index(drop=True)\n",
    "\n",
    "# create a DataLoader\n",
    "trainset_dataset = FinetuneDataset(trainset_data, tokenizer)\n",
    "testset_dataset = FinetuneDataset(testset_data, tokenizer)\n",
    "\n",
    "trainset_loader = DataLoader(trainset_dataset, batch_size=32, shuffle=True)\n",
    "testset_loader = DataLoader(testset_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3902/3902 [20:14<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 3190.6724\n",
      "Training Accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 976/976 [01:32<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3902/3902 [20:09<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 2664.1749\n",
      "Training Accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 976/976 [01:32<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3902/3902 [20:09<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 2331.5419\n",
      "Training Accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 976/976 [01:32<00:00, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertClassifier(bert_model, num_classes=5)\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.bert.parameters(), 'lr': 5e-6},\n",
    "    {'params': model.classifier.parameters(), 'lr': 5e-4}\n",
    "])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epoch_num = 3\n",
    "\n",
    "train(model, trainset_loader, testset_loader, optimizer, criterion, device, epoch_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save and upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we call the deepseek api, and set the appropriate prompt to do the sentiment analysis.\n",
    "\n",
    "we compare the accuracy with 2 kinds of system prompt.\n",
    "\n",
    "**system prompt:**\n",
    "1. zero-shot prompt:(we provide no example and ask the problems directly)\n",
    "> You are a sentiment analysis expert. Your task is to classify movie review phrases into one of five sentiment categories: negative (0), somewhat negative (1), neutral (2), somewhat positive (3), or positive (4). You should carefully consider the intensity and context of the phrases to determine the most appropriate label. The output should be in the format \"Label: \\label{number}, Sentiment: \\sentiment{text}\".\n",
    "\n",
    "2. few-shot prompt:(we provide some examples and ask the problems)\n",
    "> You are a sentiment analysis expert. Your task is to classify movie review phrases into one of five sentiment categories: negative (0), somewhat negative (1), neutral (2), somewhat positive (3), or positive (4). You should carefully consider the intensity and context of the phrases to determine the most appropriate label.  \n",
    "> \n",
    "> **Examples:**  \n",
    "> 1. Phrase: \"Terrible acting and a boring plot.\"  \n",
    ">    Output: Label: 0, Sentiment: negative  \n",
    "> \n",
    "> 2. Phrase: \"The pacing was slow, but the visuals were decent.\"  \n",
    ">    Output: Label: 1, Sentiment: somewhat negative  \n",
    "> \n",
    "> 3. Phrase: \"It was an average movie with some good moments.\"  \n",
    ">    Output: Label: 2, Sentiment: neutral  \n",
    "> \n",
    "> 4. Phrase: \"The humor was clever, and the characters were engaging.\"  \n",
    ">    Output: Label: 3, Sentiment: somewhat positive  \n",
    "> \n",
    "> 5. Phrase: \"A masterpiece with brilliant performances and a captivating story.\"  \n",
    ">    Output: Label: 4, Sentiment: positive  \n",
    "> \n",
    "> **Guidelines:**  \n",
    "> - Use the examples above as a reference for intensity and context.  \n",
    "> - Ensure your output matches the format: \"Label: \\label{number}, Sentiment: \\sentiment{text}\".  \n",
    "\n",
    "**user prompt:**\n",
    "> Classify the sentiment of this movie review phrase:\n",
    "> \n",
    "> Phrase: \"The plot was predictable, but the visuals were stunning.\"\n",
    "> \n",
    "> Output format: Label: \\label{number}, Sentiment: \\sentiment{text}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
